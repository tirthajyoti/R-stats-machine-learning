# Number of entries in the Truth Table
N<- 1000
# Fraction of 1's generated by random for constructing the Truth Table
frac.ones<-0.5
# Fraction of random flips to be performed later
frac.flip<-0.1

# Generation of inputs
x1<- rbinom(N,1,frac.ones)
x2<- rbinom(N,1,frac.ones)
x3<- rbinom(N,1,frac.ones)
x4<- rbinom(N,1,frac.ones)

# Boolean function
y<- xor(x1,x2)&xor(x3,x4)|(x2&x4)&((xor(x2,x3)|(x1&x4)))

# Random flipping of Y-bit
y.flip<- rbinom(N,1,frac.flip)
y<- xor(y,y.flip)
d1<- data.frame(x1,x2,x3,x4,Y=as.numeric(y))

# Test/Train split
#set.seed(123)
library(caTools)
sample.N <- sample.split(d1$Y,SplitRatio = 0.7)
train.d1 <- subset(d1,sample.N==T)
test.d1<- subset(d1, sample.N==F)
testnn.d1<- test.d1

# Logistic regression model, confusion matrix, and histogram of predicted probabilities
# Logistic model does much better when factorial expression is used i.e. x1*x2*x3*x4, try yourself
m1<- glm(Y~x1+x2+x3+x4, data=train.d1, family = binomial(link = 'logit'))
test.d1$predicted<- predict(m1,test.d1, type='response')
confusion.matrix1<- as.matrix(table(test.d1$Y, test.d1$predicted>0.5))
precision1 <- (confusion.matrix1[1,1]+confusion.matrix1[2,2])/(sum(confusion.matrix1))
print (precision1)
#hist(test.d1$predicted, breaks=20, xlim=c(0,1.0))

# Neural Net model, confusion matrix, and histogram of predicted probabilities
library(neuralnet)
# Model parameters (feel free to experiment with them)
# Number of hidden layers = 2
# Number of neurons in hidden layer = 5 and 3
# Maximum steps for the training of the neural network = 10000
# Activation function = Logistic
# Number of repetitions for the neural network's training = 5
# Algorithm = Resilient backpropagation with weight backtracking
# Error function = Sum-of-squared error
nn1<- neuralnet(Y~x1+x2+x3+x4, hidden=c(5,3), data=train.d1, stepmax = 10000,
                act.fct='logistic',linear.output = F, rep=5, 
                threshold = 0.01, algorithm = 'rprop+', err.fct = 'sse')
test.nn<- compute(nn1, testnn.d1[1:4])
testnn.d1$predicted<- test.nn[[2]]
confusion.matrix.nn<- as.matrix(table(testnn.d1$Y, testnn.d1$predicted>0.5))
precision.nn <- (confusion.matrix.nn[1,1]+confusion.matrix.nn[2,2])/(sum(confusion.matrix.nn))
print (precision.nn)
#hist(testnn.d1$predicted, breaks=20, xlim = c(0,1.0))

# Comparing the predictions of Logistic regression and Neural Net by Rug Plot
# Goal is to show wider separation of probability values predicted by Neural Net,
#as compared to Logistic Regression 
df.pred <- data.frame(NN.Pred=testnn.d1$predicted, Log.Pred=test.d1$predicted)
library(ggplot2)
pl1<- ggplot(df.pred, aes(NN.Pred, Log.Pred))+ geom_jitter(size=3)
pl1<- pl1+ geom_rug(size=1, color='red', alpha=0.5, position = 'jitter')
pl1<- pl1+ coord_cartesian(xlim = c(0,1), ylim = c(0,1))
pl1<- pl1+ xlab("Neural Net predicted probability values") + ylab("Logistic Regression predicted probability values")
pl1<- pl1+ theme(axis.title=element_text(size=14,face="bold"), axis.text = element_text(colour = "red", size = rel(1.5)))
print(pl1)
#plot(test.d1$predicted, testnn.d1$predicted)
#print(cor(test.d1$predicted, testnn.d1$predicted)[1,1])

# RMSE errors calculation (since predicted values are probabilities, we simply take the
#difference betwwen actual result bit and the predicted probability value)
# It is clear that this RMSE cannot capture the superiority of Neural Net model
rmse.glm<- sqrt(mean(sum(test.d1$predicted-test.d1$Y)^2))
rmse.nn<- sqrt(mean(sum(testnn.d1$predicted-testnn.d1$Y)^2))

# Plotting Neural Net (for fun)
#plot(nn1, col.hidden = 'green', rep='best')



  
  
  
  